{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1ReyURLrMKo"
      },
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJuh2e9praxr"
      },
      "source": [
        "class MHA(nn.Module):\n",
        "    \"\"\"Heart of https://arxiv.org/pdf/2006.16236.pdf\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, n_heads, use_cos, kernel, \n",
        "                 dropout, denom_eps, bias):\n",
        "        super(MHA, self).__init__()\n",
        "        assert d_model % n_heads == 0, 'd_model must be a multiple of n_heads'\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.d_head = self.d_model // self.n_heads\n",
        "        self.denom_eps = denom_eps\n",
        "\n",
        "        if kernel == 'relu':\n",
        "            self.kernel = self.relu_kernel\n",
        "        elif kernel == 'elu':\n",
        "            self.kernel = self.elu_kernel\n",
        "        else:\n",
        "            raise NotImplementedError(\n",
        "                \"The only options for 'kernel' are 'relu and 'elu'.\")\n",
        "            \n",
        "        if use_cos:\n",
        "            self.attention_func = self.cos_linear_attention\n",
        "        else:\n",
        "            self.attention_func = self.linear_attention\n",
        "\n",
        "        self.w_qkv = nn.Linear(d_model, 3 * d_model, bias=bias)\n",
        "        self.w_o = nn.Linear(d_model, d_model, bias=bias)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def apply_mask(self, x, mask):\n",
        "        # x -> [batch_size, seq_len, _]\n",
        "        # mask -> [batch_size, seq_len, 1] or None\n",
        "        if not mask is None:\n",
        "            #x.masked_fill_(~mask, 0)\n",
        "            x = x.masked_fill(~mask, 0)\n",
        "        return x\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        batch_size, seq_len = x.shape[:2]\n",
        "        # x -> [batch_size, seq_len, d_model]\n",
        "        x = x.view(batch_size, seq_len, self.n_heads, self.d_head)\n",
        "        # x -> [batch_size, seq_len, n_heads, d_head]\n",
        "        return x\n",
        "\n",
        "    def join_heads(self, x):\n",
        "        batch_size, seq_len = x.shape[:2]\n",
        "        # x -> [batch_size, seq_len, n_heads, d_head]\n",
        "        x = x.view(batch_size, seq_len, self.d_model).contiguous()\n",
        "        # x -> [batch_size, seq_len, d_model]\n",
        "        return x\n",
        "\n",
        "    def elu_kernel(self, x):\n",
        "        return F.elu(x) + 1\n",
        "\n",
        "    def relu_kernel(self, x):\n",
        "        return F.relu(x)\n",
        "\n",
        "    def linear_attention(self, q, k, v, weights=None):\n",
        "        # stolen from \n",
        "        # https://github.com/tensorflow/models/blob/master/official/nlp/modeling/layers/kernel_attention.py\n",
        "        # q, k, v -> [batch_size, seq_len, n_heads, d_head]\n",
        "        kv = torch.einsum('bsnx,bsnz->bnxz', k, v)\n",
        "        # kv -> [batch_size, n_heads, d_head, d_head]\n",
        "        # add dropout here\n",
        "        denominator = 1.0 / (torch.einsum('bsnd,bnd->bsn', q, k.sum(axis=1)) + self.denom_eps)\n",
        "        # denominator -> [batch_size, seq_len, n_heads]\n",
        "\n",
        "        output = torch.einsum('bsnx,bnxz,bsn->bsnz', q, kv, denominator).contiguous()\n",
        "        # output -> [batch_size, seq_len, n_heads, d_head]\n",
        "\n",
        "        return output\n",
        "\n",
        "    def cos_linear_attention(self, q, k, v, weights):\n",
        "        # q, k, v -> [batch_size, seq_len, n_heads, d_head]\n",
        "        cos, sin = weights\n",
        "        # cos, sin -> [batch_size, seq_len]\n",
        "        q_cos = torch.einsum('bsnd,bs->bsnd', q, cos)\n",
        "        q_sin = torch.einsum('bsnd,bs->bsnd', q, sin)\n",
        "        k_cos = torch.einsum('bsnd,bs->bsnd', k, cos)\n",
        "        k_sin = torch.einsum('bsnd,bs->bsnd', k, sin)\n",
        "        # q_cos, q_sin, k_cos, k_sin -> [batch_size, seq_len, n_heads, d_head]\n",
        "\n",
        "        kv_cos = torch.einsum('bsnx,bsnz->bnxz', k_cos, v)\n",
        "        # kv_cos -> [batch_size, n_heads, d_head, d_head]\n",
        "        qkv_cos = torch.einsum('bsnx,bnxz->bsnz', q_cos, kv_cos)\n",
        "        # qkv_cos -> [batch_size, seq_len, n_heads, d_head]\n",
        "\n",
        "        kv_sin = torch.einsum('bsnx,bsnz->bnxz', k_sin, v)\n",
        "        # kv_sin -> [batch_size, n_heads, d_head, d_head]\n",
        "        qkv_sin = torch.einsum('bsnx,bnxz->bsnz', q_sin, kv_sin)\n",
        "        # qkv_sin -> [batch_size, seq_len, n_heads, d_head]\n",
        "\n",
        "        # denominator\n",
        "        denominator = 1.0 / (torch.einsum('bsnd,bnd->bsn', q_cos, k_cos.sum(axis=1)) \n",
        "            + torch.einsum('bsnd,bnd->bsn', q_sin, k_sin.sum(axis=1))\n",
        "            + self.denom_eps)\n",
        "        # denominator -> [batch_size, seq_len, n_heads]\n",
        "        \n",
        "        output = torch.einsum('bsnz,bsn->bsnz', qkv_cos + qkv_sin, denominator).contiguous()\n",
        "        # output -> [batch_size, seq_len, n_heads, d_head]\n",
        "        return output        \n",
        "\n",
        "    def forward(self, x, mask, weights):\n",
        "        # x -> [batch_size, seq_len, d_model]\n",
        "        # mask -> [batch_size, seq_len, 1] or None\n",
        "        q, k, v = torch.chunk(self.w_qkv(x), 3, -1) \n",
        "        # q, k, v -> [batch_size, seq_len, d_model]\n",
        "\n",
        "        q = self.kernel(self.split_heads(q))\n",
        "        k = self.kernel(self.split_heads(k))\n",
        "        #v = self.apply_mask(self.split_heads(v), mask)\n",
        "        v = self.split_heads(self.apply_mask(v, mask))\n",
        "        # q, k, v -> [batch_size, seq_len, n_heads, d_head]\n",
        "\n",
        "        x = self.attention_func(q, k, v, weights)\n",
        "        # x -> [batch_size, seq_len, n_heads, d_head]\n",
        "        x = self.join_heads(x)\n",
        "        x = self.dropout(self.w_o(x))\n",
        "        # x -> [batch_size, seq_len, d_model]\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class FFN(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, ffn_ratio, dropout, bias):\n",
        "        super(FFN, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(d_model, ffn_ratio * d_model, bias=bias),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(ffn_ratio * d_model, d_model),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x -> [batch_size, seq_len, d_model]\n",
        "        x = self.layers(x)\n",
        "        # x -> [batch_size, seq_len, d_model]\n",
        "        return x\n",
        "\n",
        "\n",
        "class MHA_block(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements the Pre-LN Architecture as suggested here:\n",
        "    https://arxiv.org/pdf/2002.04745.pdf\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, n_heads, use_cos, kernel, dropout, \n",
        "                 ffn_ratio, ln_eps, denom_eps, bias, rezero):\n",
        "\n",
        "        super(MHA_block, self).__init__()\n",
        "        self.ln1 = nn.LayerNorm(d_model, eps=ln_eps)\n",
        "        self.ln2 = nn.LayerNorm(d_model, eps=ln_eps)\n",
        "\n",
        "        self.mha = MHA(\n",
        "            d_model, n_heads, use_cos, kernel, dropout, denom_eps, bias)  \n",
        "        self.ffn = FFN(d_model, ffn_ratio, dropout, bias)\n",
        "\n",
        "        # ReZero is All You Need\n",
        "        # https://arxiv.org/pdf/2003.04887.pdf\n",
        "        # https://github.com/majumderb/rezero\n",
        "        if rezero:\n",
        "            self.alpha = nn.Parameter(torch.Tensor([0]))\n",
        "        else:\n",
        "            self.register_buffer('alpha', torch.Tensor([1]))\n",
        "\n",
        "    def forward(self, x, mask, weights):\n",
        "\n",
        "        # x -> [batch_size, seq_len, d_model]\n",
        "        fx = self.alpha * self.mha(self.ln1(x), mask, weights)\n",
        "        x = x + fx\n",
        "\n",
        "        fx = self.alpha * self.ffn(self.ln2(x))\n",
        "        x = x + fx\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Kernel_transformer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, n_heads, use_cos, kernel, dropout, \n",
        "                 ffn_ratio, n_layers, n_emb, tie_emb, ln_eps, denom_eps, \n",
        "                 bias, rezero, mn_ratio=1.05):\n",
        "        super(Kernel_transformer, self).__init__()\n",
        "\n",
        "        self.mn_ratio = mn_ratio\n",
        "        # Tie input & output embeddings\n",
        "        # https://arxiv.org/abs/1608.05859\n",
        "        self.emb_in = nn.Embedding(n_emb, d_model)\n",
        "        self.emb_out = nn.Linear(d_model, n_emb)\n",
        "        if tie_emb:\n",
        "            self.emb_out.weight = self.emb_in.weight\n",
        "\n",
        "        self.mha_blocks = nn.ModuleList(\n",
        "            [MHA_block(\n",
        "                d_model, n_heads, use_cos, kernel, dropout, \n",
        "                ffn_ratio, ln_eps, denom_eps, bias, rezero\n",
        "                ) for _ in range(n_layers)]\n",
        "        )\n",
        "        \n",
        "        # Trick to get model device. Stolen from:\n",
        "        # https://stackoverflow.com/questions/58926054/how-to-get-the-device-type-of-a-pytorch-module-conveniently\n",
        "        self.dummy_param = nn.Parameter(torch.empty(0))\n",
        "\n",
        "    def dev(self):\n",
        "        \"\"\"Returns the device where the model is stored\"\"\"\n",
        "        return self.dummy_param.device\n",
        "\n",
        "    def get_mask(self, lens, max_len):\n",
        "        # lens -> [batch_size]\n",
        "        mask = torch.arange(max_len, device=self.dev())[None, :] < lens[:, None]\n",
        "        # mask -> [batch_size, max_len]\n",
        "        mask = mask[..., None]\n",
        "        #mask = torch.logical_not(mask[..., None, None])\n",
        "        # mask -> [batch_size, max_len, 1]\n",
        "        return mask\n",
        "\n",
        "    def get_cos(self, lens, max_len):\n",
        "        # lens -> [batch_size]\n",
        "        # For each sample x in the batch, calculate M(x) = MN_ratio * len(x)\n",
        "        M = self.mn_ratio * lens\n",
        "        # M -> [batch_size]\n",
        "        idxs = math.pi / 2 * torch.arange(max_len, device=self.dev())\n",
        "        # idxs -> [max_len]\n",
        "        idxs = torch.outer(M, idxs)#[..., None, None]\n",
        "        # idxs -> [batch_size, max_len]\n",
        "\n",
        "        cos = torch.cos(idxs)\n",
        "        sin = torch.sin(idxs)\n",
        "        # cos, sin -> [batch_size, max_len, 1, 1]\n",
        "\n",
        "        return cos, sin\n",
        "\n",
        "    def forward(self, input_idxs, mask, weights):\n",
        "        # input_idxs -> [batch_size, seq_len]\n",
        "        # mask -> [batch_size, max_len, 1] or None\n",
        "        # weights ->  (tuple 2 X [batch_size, seq_len]) or None\n",
        "\n",
        "        x = self.emb_in(input_idxs)\n",
        "        for block in self.mha_blocks:\n",
        "            x = block(x, mask, weights)\n",
        "\n",
        "        x = self.emb_out(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjS4BzsCwFnh"
      },
      "source": [
        "lens = torch.tensor([69, 20, 97])\n",
        "max_len = lens.max().item()\n",
        "test = model.get_cos(lens, max_len)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIcZ_qvtxOWV",
        "outputId": "efb6cca7-bbe1-4280-abea-90ee5ff3aad7"
      },
      "source": [
        "test[0].mean()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0017)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "RAOicfaiwbLt",
        "outputId": "306cd1e8-e4cf-42fe-85b4-d9aed0606f70"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "test1_np = test[0].numpy()\n",
        "test2_np = test[1].numpy()\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.imshow(test1_np)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.imshow(test2_np)\n",
        "plt.show()\n"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23SWmuJEvYw_"
      },
      "source": [
        "d_model = 16\n",
        "n_heads = 2\n",
        "use_cos = True\n",
        "kernel = 'relu'\n",
        "dropout = 0.2\n",
        "ffn_ratio = 4\n",
        "n_layers = 2\n",
        "n_emb = 100\n",
        "tie_emb = True\n",
        "ln_eps = 1e-6\n",
        "denom_eps = 1e-6\n",
        "bias = False\n",
        "rezero = True\n",
        "mn_ratio=1.05\n",
        "\n",
        "seq_len = 1000\n",
        "batch_size = 4\n",
        "\n"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V6l6TJ1P8Sf"
      },
      "source": [
        "model = Kernel_transformer(\n",
        "    d_model=d_model,\n",
        "    n_heads=n_heads, \n",
        "    use_cos=use_cos,\n",
        "    kernel=kernel, \n",
        "    dropout=dropout, \n",
        "    ffn_ratio=ffn_ratio, \n",
        "    n_layers=n_layers,\n",
        "    n_emb=n_emb,\n",
        "    tie_emb=tie_emb,\n",
        "    ln_eps=ln_eps, \n",
        "    denom_eps=denom_eps, \n",
        "    bias=bias, \n",
        "    rezero=rezero)"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCgDAnfB8tfA"
      },
      "source": [
        "input_idxs = torch.randint(0, n_emb, [batch_size, seq_len])\n",
        "lens = torch.randint(1, seq_len, [batch_size])\n",
        "\n",
        "mask = model.get_mask(lens, seq_len)\n",
        "weights = model.get_cos(lens, seq_len)\n",
        "\n",
        "output = model(input_idxs, mask, weights)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KToqkRO9hUS",
        "outputId": "9e3730e9-6480-47e2-c1af-ac15290cf9f1"
      },
      "source": [
        "output.shape"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 1000, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVTWJAfavvIR",
        "outputId": "7d8650cd-58ea-4eb6-b26b-1d9510d740d2"
      },
      "source": [
        "batch = torch.rand((batch_size, seq_len, d_model))\n",
        "print(batch.shape)\n",
        "lens = torch.tensor([1, 3, 2, 1])\n",
        "mask = model.get_mask(lens, seq_len)\n",
        "print(mask.shape)\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 16])\n",
            "torch.Size([4, 3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krWcrKzhwqgi",
        "outputId": "e82ccb5d-4138-4f9c-8fa1-443838567282"
      },
      "source": [
        "output = model(batch, mask)\n",
        "print(output.shape)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxK8CjO-wCdL",
        "outputId": "cfa8f968-e33a-4fc8-f5ec-ec99713b3404"
      },
      "source": [
        "masked_batch = model.apply_mask(batch, mask)\n",
        "print(masked_batch)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.9638, 0.2398, 0.0241, 0.4604, 0.7244, 0.7315, 0.2613, 0.4878,\n",
            "          0.9803, 0.0258, 0.0206, 0.0219, 0.2968, 0.4857, 0.6981, 0.2027],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "        [[0.7327, 0.2265, 0.6460, 0.1862, 0.9855, 0.8580, 0.3619, 0.7935,\n",
            "          0.0060, 0.6024, 0.0805, 0.4093, 0.0561, 0.8490, 0.9586, 0.4716],\n",
            "         [0.7183, 0.1173, 0.7593, 0.5132, 0.6751, 0.1955, 0.3137, 0.3406,\n",
            "          0.7958, 0.2284, 0.6372, 0.4300, 0.2027, 0.9165, 0.8389, 0.8188],\n",
            "         [0.9290, 0.8413, 0.5069, 0.0595, 0.0059, 0.0356, 0.4498, 0.0824,\n",
            "          0.1026, 0.3432, 0.1345, 0.4369, 0.1351, 0.6864, 0.0215, 0.5408]],\n",
            "\n",
            "        [[0.4006, 0.1905, 0.7883, 0.8001, 0.1851, 0.8474, 0.8908, 0.5399,\n",
            "          0.1389, 0.4567, 0.3571, 0.0485, 0.0918, 0.9676, 0.3022, 0.7726],\n",
            "         [0.4523, 0.3758, 0.3709, 0.4534, 0.7516, 0.3824, 0.9377, 0.8032,\n",
            "          0.6450, 0.4015, 0.4323, 0.4816, 0.2166, 0.9133, 0.0845, 0.3430],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "        [[0.0305, 0.0416, 0.0616, 0.3577, 0.5426, 0.6305, 0.5484, 0.2389,\n",
            "          0.0083, 0.8963, 0.5928, 0.9142, 0.3804, 0.1459, 0.2052, 0.6814],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20FpV_kB3UPX",
        "outputId": "21cf7cf4-2c55-40c7-d897-2c71ae5acb6e"
      },
      "source": [
        "lens = torch.tensor([5, 8, 2])\n",
        "torch.arange(lens.max(), device=self.dev())[None, :] < lens[:, None]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ True,  True,  True,  True,  True, False, False, False],\n",
              "        [ True,  True,  True,  True,  True,  True,  True,  True],\n",
              "        [ True,  True, False, False, False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHddwETesmJK"
      },
      "source": [
        "batch_size = 2\n",
        "seq_len = 4\n",
        "d_model = 5\n",
        "\n",
        "x = torch.arange(batch_size * seq_len * 3 * d_model).reshape(batch_size, seq_len, 3 * d_model)\n",
        "\n",
        "y = torch.chunk(x, 3, -1)\n",
        "\n",
        "print(x)\n",
        "\n",
        "print(y)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8WrImPpvV-z",
        "outputId": "738b117c-cd48-44be-8135-34b7865ed0df"
      },
      "source": [
        "a, b = x.shape[:2]\n",
        "type(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "int"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}